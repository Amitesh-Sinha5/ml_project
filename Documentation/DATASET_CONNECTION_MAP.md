# Dataset Connection Map - ML_HACKATHON.ipynb

## ðŸ—ºï¸ Data Flow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    PRIMARY DATASETS                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Data/corpus.txt  (~50,000 words)  â†’  corpus_words (Python list)â”‚
â”‚  Data/test.txt    (test set)       â†’  test_words   (Python list)â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    CELL 2: Data Loading                          â”‚
â”‚  Input:  Data/corpus.txt, Data/test.txt (text files)            â”‚
â”‚  Output: corpus_words, test_words (lists)                       â”‚
â”‚  Format: ['apple', 'banana', 'cherry', ...]                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                                   â”‚
          â–¼                                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   CELLS 3-10: EDA   â”‚           â”‚  CELLS 11-12: HMM   â”‚
â”‚   (Exploratory      â”‚           â”‚  (Model Training)   â”‚
â”‚   Data Analysis)    â”‚           â”‚                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤           â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Uses: corpus_words  â”‚           â”‚ Uses: corpus_words  â”‚
â”‚       test_words    â”‚           â”‚                     â”‚
â”‚                     â”‚           â”‚ Trains:             â”‚
â”‚ Outputs:            â”‚           â”‚ - Position probs    â”‚
â”‚ - Visualizations    â”‚           â”‚ - Bigram probs      â”‚
â”‚ - Statistics        â”‚           â”‚ - Trigram probs     â”‚
â”‚ - eda_results.pkl   â”‚           â”‚                     â”‚
â”‚                     â”‚           â”‚ Outputs:            â”‚
â”‚ Insights:           â”‚           â”‚ - hmm (object)      â”‚
â”‚ - Letter freq       â”‚           â”‚ - Model metrics     â”‚
â”‚ - Position patterns â”‚           â”‚                     â”‚
â”‚ - N-grams           â”‚           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚ - Difficulty        â”‚                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚
          â”‚                                 â”‚
          â”‚                                 â–¼
          â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                   â”‚  CELLS 13-14: RL Setup  â”‚
          â”‚                   â”‚  (Agent + Environment)  â”‚
          â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”‚                   â”‚ Uses: corpus_words      â”‚
          â”‚                   â”‚       hmm (from Cell 11)â”‚
          â”‚                   â”‚                         â”‚
          â”‚                   â”‚ Creates:                â”‚
          â”‚                   â”‚ - HangmanEnvironment    â”‚
          â”‚                   â”‚ - EnhancedHangmanAgent  â”‚
          â”‚                   â”‚                         â”‚
          â”‚                   â”‚ Agent uses:             â”‚
          â”‚                   â”‚ - Q-table (initially âˆ…) â”‚
          â”‚                   â”‚ - HMM probabilities     â”‚
          â”‚                   â”‚ - EDA heuristics        â”‚
          â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                             â”‚
          â”‚                             â–¼
          â”‚                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚                   â”‚  CELLS 15-16: Training  â”‚
          â”‚                   â”‚  (Q-Learning)           â”‚
          â”‚                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
          â”‚                   â”‚ Uses: corpus_words      â”‚
          â”‚                   â”‚       agent (Cell 14)   â”‚
          â”‚                   â”‚       env (Cell 13)     â”‚
          â”‚                   â”‚                         â”‚
          â”‚                   â”‚ Process:                â”‚
          â”‚                   â”‚ 10,000 episodes         â”‚
          â”‚                   â”‚ Each episode:           â”‚
          â”‚                   â”‚ 1. Sample word from     â”‚
          â”‚                   â”‚    corpus_words         â”‚
          â”‚                   â”‚ 2. Agent plays game     â”‚
          â”‚                   â”‚ 3. Update Q-table       â”‚
          â”‚                   â”‚                         â”‚
          â”‚                   â”‚ Outputs:                â”‚
          â”‚                   â”‚ - training_history      â”‚
          â”‚                   â”‚ - Trained Q-table       â”‚
          â”‚                   â”‚ - Visualizations        â”‚
          â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                             â”‚
          â”‚                             â–¼
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                        â”‚                         â”‚
                                        â–¼                         â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  CELLS 17-18: Evaluate  â”‚  â”‚  CELL 22: Baseline  â”‚
                          â”‚  (Test Set Performance) â”‚  â”‚  (Comparison)       â”‚
                          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                          â”‚ Uses: test_words        â”‚  â”‚ Uses: test_words    â”‚
                          â”‚       trained agent     â”‚  â”‚       corpus_words  â”‚
                          â”‚                         â”‚  â”‚                     â”‚
                          â”‚ Process:                â”‚  â”‚ Creates:            â”‚
                          â”‚ For each test word:     â”‚  â”‚ - Baseline agent    â”‚
                          â”‚ 1. Agent plays game     â”‚  â”‚   (frequency only)  â”‚
                          â”‚ 2. Record metrics       â”‚  â”‚                     â”‚
                          â”‚                         â”‚  â”‚ Compares:           â”‚
                          â”‚ Outputs:                â”‚  â”‚ - Enhanced vs       â”‚
                          â”‚ - eval_results          â”‚  â”‚   Baseline          â”‚
                          â”‚ - Success rate          â”‚  â”‚ - Performance gain  â”‚
                          â”‚ - Final score           â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                        â”‚
                                        â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚  CELLS 19-21: Analysis  â”‚
                          â”‚  (Detailed Reporting)   â”‚
                          â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
                          â”‚ Uses: eval_results      â”‚
                          â”‚       training_history  â”‚
                          â”‚       all EDA data      â”‚
                          â”‚                         â”‚
                          â”‚ Generates:              â”‚
                          â”‚ - 6 visualization plots â”‚
                          â”‚ - Failure analysis      â”‚
                          â”‚ - All .pkl files        â”‚
                          â”‚ - Reports (.txt)        â”‚
                          â”‚ - CSV results           â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ“Š Dataset Usage Summary

### **Data/corpus.txt** â†’ **corpus_words**

| Cell | Purpose        | How Used                         |
| ---- | -------------- | -------------------------------- |
| 2    | Load data      | Read file, create list           |
| 3-10 | EDA            | Analyze patterns, statistics     |
| 11   | HMM Training   | Train position-specific models   |
| 13   | RL Environment | Word pool for game simulation    |
| 15   | RL Training    | Sample words for 10,000 episodes |
| 22   | Baseline       | Train baseline frequency agent   |

**Total Uses**: 7 major components
**Purpose**: Model training and learning

---

### **Data/test.txt** â†’ **test_words**

| Cell  | Purpose    | How Used                     |
| ----- | ---------- | ---------------------------- |
| 2     | Load data  | Read file, create list       |
| 3-10  | EDA        | Compare with corpus stats    |
| 17-18 | Evaluation | Final performance testing    |
| 19-20 | Analysis   | Detailed result analysis     |
| 22    | Baseline   | Compare baseline performance |
| 23    | Demo       | Interactive demonstrations   |

**Total Uses**: 6 major components
**Purpose**: Model evaluation and validation

---

## ðŸ”„ Data Transformations

### **Raw Text Files â†’ Python Lists**

```
Data/corpus.txt:
apple
banana
cherry

â†“ (Cell 2)

corpus_words = ['apple', 'banana', 'cherry']
```

### **Words â†’ Length Statistics**

```
corpus_words = ['apple', 'banana', 'cherry']

â†“ (Cell 3)

corpus_lengths = [5, 6, 6]
Mean: 5.67, Median: 6
```

### **Words â†’ Letter Frequencies**

```
corpus_words = ['apple', 'banana', 'cherry']

â†“ (Cell 4)

corpus_letter_freq = Counter({
    'a': 4, 'p': 2, 'e': 2, 'l': 1,
    'b': 1, 'n': 2, 'c': 1, 'h': 1,
    'r': 2, 'y': 1
})
```

### **Words â†’ HMM Position Probabilities**

```
corpus_words = ['apple', 'banana', 'cherry']

â†“ (Cell 11)

hmm.models[5] = {  # 5-letter words
    'position_probs': {
        0: {'a': 0.4, 'c': 0.2, ...},  # First position
        1: {'p': 0.3, 'h': 0.2, ...},  # Second position
        ...
    }
}
```

### **Words â†’ Q-Table States**

```
Word: "apple" with guesses ['a', 'p']
Revealed: "app__"

â†“ (Cell 14)

State: ("011__", length=5, lives=6, guessed=2)
Q-table[state] = {'l': 0.8, 'e': 0.9, ...}
```

---

## ðŸ“ˆ Data Dependencies Graph

```
corpus.txt â”€â”€â”¬â”€â”€> corpus_words â”€â”€â”¬â”€â”€> EDA (Cells 3-10)
             â”‚                    â”‚
test.txt â”€â”€â”€â”€â”´â”€â”€> test_words â”€â”€â”€â”€â”¤
                                 â”‚
                                 â”œâ”€â”€> HMM Training (Cell 11)
                                 â”‚         â”‚
                                 â”‚         â”œâ”€â”€> Position Probs
                                 â”‚         â”œâ”€â”€> Bigram Probs
                                 â”‚         â””â”€â”€> Trigram Probs
                                 â”‚
                                 â”œâ”€â”€> RL Environment (Cell 13)
                                 â”‚         â”‚
                                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€> RL Training (Cell 15)
                                               â”‚
                                               â”œâ”€â”€> Q-Table
                                               â””â”€â”€> Trained Agent
                                                         â”‚
                  test_words â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€> Evaluation
                                                               (Cells 17-18)
```

---

## ðŸŽ¯ Critical Data Checkpoints

### **Checkpoint 1: Data Loading (Cell 2)**

```python
assert len(corpus_words) > 0, "Corpus not loaded!"
assert len(test_words) > 0, "Test set not loaded!"
print(f"âœ“ Loaded {len(corpus_words)} training words")
print(f"âœ“ Loaded {len(test_words)} test words")
```

### **Checkpoint 2: HMM Training (Cell 11)**

```python
assert len(hmm.models) > 0, "HMM not trained!"
assert len(hmm.bigram_probs) > 0, "Bigrams missing!"
print(f"âœ“ HMM trained with {len(hmm.models)} length-specific models")
```

### **Checkpoint 3: RL Training (Cell 15)**

```python
assert len(agent.q_table) > 0, "Q-table empty!"
assert len(training_history['rewards']) == 10000, "Training incomplete!"
print(f"âœ“ Agent trained for 10,000 episodes")
print(f"âœ“ Q-table size: {len(agent.q_table)} states")
```

### **Checkpoint 4: Evaluation (Cell 18)**

```python
assert eval_results['games_played'] == len(test_words), "Evaluation incomplete!"
print(f"âœ“ Evaluated on {eval_results['games_played']} test words")
print(f"âœ“ Success rate: {eval_results['success_rate']*100:.2f}%")
```

---

## ðŸ—‚ï¸ Intermediate Data Products

| Variable             | Created | Type                 | Description                    |
| -------------------- | ------- | -------------------- | ------------------------------ |
| `corpus_words`       | Cell 2  | list                 | Training words from corpus.txt |
| `test_words`         | Cell 2  | list                 | Test words from test.txt       |
| `corpus_lengths`     | Cell 3  | list                 | Word lengths for EDA           |
| `corpus_letter_freq` | Cell 4  | Counter              | Letter frequency counts        |
| `hmm`                | Cell 11 | EnhancedHangmanHMM   | Trained HMM model              |
| `agent`              | Cell 14 | EnhancedHangmanAgent | RL agent                       |
| `training_history`   | Cell 15 | dict                 | Training metrics               |
| `eval_results`       | Cell 18 | dict                 | Evaluation results             |

---

## ðŸ’¾ Saved Files (Dataset Derivatives)

| File                              | Source Dataset              | Contains       |
| --------------------------------- | --------------------------- | -------------- |
| `eda_results.pkl`                 | corpus_words, test_words    | EDA statistics |
| `enhanced_hmm_model.pkl`          | corpus_words                | Trained HMM    |
| `q_table.pkl`                     | corpus_words (via training) | Q-values       |
| `comprehensive_results.pkl`       | test_words (via eval)       | All metrics    |
| `detailed_evaluation_results.csv` | test_words                  | Per-game data  |

---

## ðŸ” Dataset Quality Checks

### **Corpus.txt Requirements**:

- âœ… One word per line
- âœ… Lowercase letters only
- âœ… No special characters
- âœ… No empty lines
- âœ… Minimum 1,000 words (recommended: 10,000+)

### **Test.txt Requirements**:

- âœ… Same format as corpus.txt
- âœ… Different words from corpus (no overlap recommended)
- âœ… Minimum 100 words (recommended: 500+)
- âœ… Representative of corpus distribution

### **Validation (Cell 2)**:

```python
# Character validation
corpus_chars = set(''.join(corpus_words))
assert corpus_chars.issubset(set(string.ascii_lowercase)), "Invalid characters!"

# Size validation
assert len(corpus_words) >= 1000, "Corpus too small!"
assert len(test_words) >= 100, "Test set too small!"
```

---

## ðŸ“– How to Trace Data Usage

### **Example: Letter 'e' through pipeline**

1. **Cell 2**: 'e' appears in corpus words

   ```
   corpus.txt: "apple\n..." â†’ corpus_words = ['apple', ...]
   ```

2. **Cell 4**: 'e' counted in frequency analysis

   ```
   corpus_letter_freq['e'] = 12543 (count in corpus)
   ```

3. **Cell 11**: 'e' probabilities learned by HMM

   ```
   hmm.models[5]['position_probs'][4]['e'] = 0.25
   (25% chance 'e' at position 4 in 5-letter words)
   ```

4. **Cell 15**: Agent learns when to guess 'e'

   ```
   Q[state, 'e'] = 0.85 (high value for guessing 'e')
   ```

5. **Cell 18**: 'e' guessed correctly on test words
   ```
   eval_results shows 'e' in top-5 most successful guesses
   ```

---

## ðŸŽ“ Summary

**Primary Datasets**:

- `Data/corpus.txt` â†’ Training (HMM + RL)
- `Data/test.txt` â†’ Evaluation (unseen data)

**Data Flow**:

1. Load â†’ 2. Analyze â†’ 3. Train â†’ 4. Evaluate â†’ 5. Report

**Key Transformations**:

- Words â†’ Statistics (EDA)
- Words â†’ Probabilities (HMM)
- Words â†’ Experiences (RL)
- Experiences â†’ Q-values (Learning)
- Test words â†’ Metrics (Evaluation)

**All data connections clearly documented in cells!**
